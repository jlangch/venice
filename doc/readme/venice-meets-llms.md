# Venice meets LLMs


... work in progress ...


The examples will use:

* LangChain4J
* ChatGPT as the LLM
* Qdrant as the vector database for embeddings
* HTMX as the Web GUI library
* Running everything from the REPL


ToDo:

- [x] Cargo module for Qdrant vector DB docker container
- [x] All Venice documentation resources converted to text data
- [x] Add a HTTP client with SSE support to Venice
- [x] Document the HTTP client in the readme
- [x] Helper to install all required LangChain4J dependencies
- [x] Provide an image module to scale images for ChatGPT's Vision api
- [ ] Create a simple OpenAI client
- [ ] OpenAI console chat example
- [ ] Chat example with HTMX GUI
- [ ] Chat example with Venice doc embeddings
