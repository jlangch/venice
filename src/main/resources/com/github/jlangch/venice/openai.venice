;;;;   __    __         _
;;;;   \ \  / /__ _ __ (_) ___ ___
;;;;    \ \/ / _ \ '_ \| |/ __/ _ \
;;;;     \  /  __/ | | | | (_|  __/
;;;;      \/ \___|_| |_|_|\___\___|
;;;;
;;;;
;;;; Copyright 2017-2024 Venice
;;;;
;;;; Licensed under the Apache License, Version 2.0 (the "License");
;;;; you may not use this file except in compliance with the License.
;;;; You may obtain a copy of the License at
;;;;
;;;;     http://www.apache.org/licenses/LICENSE-2.0
;;;;
;;;; Unless required by applicable law or agreed to in writing, software
;;;; distributed under the License is distributed on an "AS IS" BASIS,
;;;; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
;;;; See the License for the specific language governing permissions and
;;;; limitations under the License.

;;;; OpenAI client without any dependencies on 3rd party libraries


(ns openai)

(load-module :http-client-j8 ['http-client-j8 :as 'hc])
(load-module :ansi)


;; =============================================================================
;; =                                                                           =
;; =                     W O R K   I N   P R O G R E S S                       =
;; =                                                                           =
;; =============================================================================


;; -----------------------------------------------------------------------------
;; MODELS 
;; -----------------------------------------------------------------------------

;; see https://platform.openai.com/docs/models/continuous-model-upgrades

(def gpt-4-turbo   "gpt-4.0-turbo")    ;; GPT-4 Turbo with Vision, 128'000 tokens
(def gpt-4         "gpt-4")            ;; GPT-4, 8'192 tokens
(def gpt-4-32k     "gpt-4-32k")        ;; GPT-4, 32'768 tokens
(def gpt-3.5-turbo "gpt-3.5-turbo")    ;; GPT-3.5, 16'385 tokens

(def dall-e-3      "dall-e-3")         ;; DALL-E 3
(def dall-e-2      "dall-e-2")         ;; DALL-E 2

(def tts-1         "tts-1")            ;; Text-to-speech 1
(def tts-1-hd      "tts-1-hd")         ;; Text-to-speech 1 HD

(def whisper-1     "whisper-1")        ;; Whisper, general-purpose speech recognition

(def text-embedding-3-large  "text-embedding-3-large")   ;; Text embedding, dimension 3'072
(def text-embedding-3-small  "text-embedding-3-small")   ;; Text embedding, dimension 1'536
(def text-embedding-ada-002  "text-embedding-ada-002")   ;; Text embedding, dimension 1'536

(def default-model "gpt-3.5-turbo")




;; -----------------------------------------------------------------------------
;; CHAT COMPLETIONS 
;; -----------------------------------------------------------------------------

;; https://platform.openai.com/docs/guides/text-generation
;; https://platform.openai.com/docs/api-reference/chat/create

(def endpoint-gpt-new "https://api.openai.com/v1/chat/completions")
(def endpoint-gpt-old "https://api.openai.com/v1/completions")


(defn 
  ^{ :arglists '(
          "(chat-completion prompt & options)" )
     :doc """
          Runs a chat completion.

          To run the request asynchronously just wrap it in a `future` and
          deref it, when the result is required.

          ¶*Parameter «prompt»*

          A prompt is either a simple string like:

          ```
          "Who won the world series in 2020?"
          ```

          or a list of prompt messages:

          ```
          [ {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Who won the world series in 2020?"},
            {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
            {"role": "user", "content": "Where was it played?"} ]
          ```

          Using prompt roles:

          | [![width: 15%]] | [![width: 85%]] |
          | *system*    | Allows to specify the way the model answers questions. ¶\
                          Classic example: "You are a helpful assistant." |
          | *user*      | Equivalent to the queries made by the user. |
          | *assistant* | Assistent roles are the model’s responses, based on the user messages. |


          ¶*Parameter request «options»*

          | [![width: 15%]]   | [![width: 85%]] |
          | :uri              | An OpenAI chat completion URI. E.g.: \
                                "https://api.openai.com/v1/chat/completions". ¶\
                                Defaults  to "https://api.openai.com/v1/chat/completions" |
          | :model            | An OpenAI model. E.g.: "gpt-3.5-turbo". Defaults \
                                to "gpt-3.5-turbo" |
          | :openai-api-key   | An optional OpenAI API Key. As default the key is read \
                                from the environment variable "OPENAI_API_KEY". |
          | :prompt-opts      | An optional map of OpenAI chat request prompt options ¶\
                                E.g. {:temperature 0.2} ¶\
                                See: [OpenAI Request Options](https://platform.openai.com/docs/api-reference/chat/create) |
          | :tools            | a list of tools. e.g.: function definitions (see OpenAI api for details) |
          | :debug            | An optional debug flag (true/false). Defaults \
                                to false. ¶\
                                In debug mode prints the HTTP request and response data |

          Tools options for passing a function:

          ```
          [ 
            { :type "function" 
              :function {
                  :name "get_current_weather"
                  :description "Get the current weather"
                  :parameters {
                      :type "object"
                      :properties {
                          :location {
                              :type "string"
                              :description "The city and state, e.g. San Francisco, CA"
                          }
                          :format {
                              :type "string"
                              :enum ["celsius", "fahrenheit"]
                              :description "The temperature unit to use. Infer this from the users location."
                          }
                      }
                      :required ["location", "format"]
                  } 
              } 
            }
          ]
          ```

          ¶*Return value*

          Returns a map with the response data:*

          | [![width: 15%]] | [![width: 85%]]                  |
          | :status         | The HTTP status (a long)         |
          | :mimetype       | The content type's mimetype      |
          | :headers        | A map of headers. key: header name, value: list \
                              of header values |
          | :message        | The final chat completion message if the OpenAI \
                              server returned the HTTP status `HTTP_OK`, else `nil` |
          | :data           | If the response' HTTP status is `HTTP_OK` \
                              the data fields contains the chat completion \
                              message. ¶\
                              If the response' HTTP status is not `HTTP_OK` \
                              the data fields contains an error message \
                              formatted as plain or JSON string. |
          
          ¶
          See:
          * [OpenAI Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)¶
          * [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat/create)
          * [OpenAI API Messages](https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages)
          * [OpenAI API Functions](https://platform.openai.com/docs/guides/function-calling)
          * [OpenAI API Functions Cookbook](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models)
          * [OpenAI API Examples](https://platform.openai.com/examples)
          * [OpenAI API Examples Prompts](https://platform.openai.com/examples?category=code)
          """ 
     :examples '(
          """
          ;; print the full OpenAI response message
          (do
            (load-module :openai)

            (let [prompt    (str "Count to 10, with a comma between each number "
                                 "and no newlines. E.g., 1, 2, 3, ...")
                  response  (openai/chat-completion prompt)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (openai/pretty-print-json (:data response)))
                (println "Error:"   (:data response)))))
          """,
          """
          ;; print only the OpenAI response message content
          (do
            (load-module :openai)

            (let [prompt    (str "Count to 10, with a comma between each number "
                                 "and no newlines. E.g., 1, 2, 3, ...")
                  response  (openai/chat-completion prompt)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (-> (:data response)
                                        (openai/extract-response-message-content)
                                        (pr-str)))
                (println "Error:"   (:data response)))))
          """,
          """
          ;; Dealing with prompt options
          (do
            (load-module :openai)

            (let [prompt   [ { :role     "system"
                               :content  "You will be provided with statements, and your task is to convert them to standard English." }
                             { :role     "user"
                               :content  "She no went to the market." } ]
                  prompt-opts { :temperature 0.7
                                :max_tokens 64
                                :top_p 1 }
                  response  (openai/chat-completion prompt 
                                                    :model "gpt-3.5-turbo" 
                                                    :prompt-opts prompt-opts)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (-> (:data response)
                                        (openai/extract-response-message-content)
                                        (openai/pretty-print-json)))
                (println "Error:"   (:data response)))))
            """ )
     :see-also '( 
          "openai/chat-completion-streaming"
          "openai/extract-response-message-content"
          "openai/pretty-print-json" ) }

  chat-completion [prompt & options]

  (let [opts            (apply hash-map options)
        _               (assert (or (nil? (:prompt-opts opts)) (map? (:prompt-opts opts))))
        uri             (:uri opts "https://api.openai.com/v1/chat/completions")
        model           (:model opts default-model)
        openai-api-key  (or (:openai-api-key opts) (openai-api-key-from-env))
        _               (validate-openai-api-key openai-api-key)
        tools           (:tools opts)
        _               (validate-tools tools)
        body            (build-prompt model prompt (:prompt-opts opts) tools {:stream false})
        debug?          (:debug opts false)
        _               (when debug? (dump-prompt body))
        response        (hc/send :post 
                          uri
                          :headers { "Content-Type" "application/json"
                                     "Authorization" (str "Bearer " openai-api-key)}
                          :body (json/write-str body)
                          :debug  debug?)
        result          { :status   (:http-status response)
                          :mimetype (:content-type-mimetype response)
                          :headers  (:headers response) } ]
   (assoc result :data  (hc/slurp-response response 
                                           :json-parse-mode :data 
                                           :json-key-fn keyword))))


(defn 
 ^{ :arglists '(
          "(chat-completion-streaming prompt handler & options)" )
     :doc """
          Runs a chat completion in streaming mode.

          Processes OpenAI server side events (SSE) and calls for every event the
          handler 'handler'.


          ¶*Parameter «prompt»*

          A prompt is either a simple string like:

          ```
          "Who won the world series in 2020?"
          ```

          or a list of prompt messages:

          ```
          [ {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Who won the world series in 2020?"},
            {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
            {"role": "user", "content": "Where was it played?"} ]
          ```

          ¶*Parameter «handler»*
       
          The event handler is a three argument function:
          
          ```
          (defn handler [delta accumulated status] ...)
          ```
         
          Handler arguments:

          | *delta*       | the delta message sent with the event |
          | *accumulated* | the accumulated message|
          | *type*        | the notification type: ¶\
                            \u00A0\u00A0 `:opened` - streaming started ¶\
                            \u00A0\u00A0 `:data` - streamed event ¶\
                            \u00A0\u00A0 `:done` - streaming done by the server |

          ¶*Parameter request «options»*
 
          | [![width: 15%]]   | [![width: 85%]] |
          | :uri              | An OpenAI chat completion URI. E.g.: \
                                "https://api.openai.com/v1/chat/completions". ¶\
                                Defaults  to "https://api.openai.com/v1/chat/completions" |
          | :model            | An OpenAI model. E.g.: "gpt-3.5-turbo". Defaults \
                                to "gpt-3.5-turbo" |
          | :openai-api-key   | An optional OpenAI API Key. As default the key is read \
                                from the environment variable "OPENAI_API_KEY". |
          | :sync             | if *true* runs the request syncronously and waits \
                                until the full message response is available. ¶\
                                if *false* runs the request asyncronously and \
                                returns immediately with the response :data \
                                field holding a `future` that can be deref'd  \
                                (with an optional timeout) to get the full \
                                message. ¶\
                                Defaults to *true* |
          | :prompt-opts      | An optional map of OpenAI chat request prompt options ¶\
                                E.g. {:temperature 0.2} ¶\
                                See: [OpenAI Request Options](https://platform.openai.com/docs/api-reference/chat/create) |
          | :debug            | An optional debug flag (true/false). Defaults \
                                to false. ¶\
                                In debug mode prints the HTTP request and response data |
 
          ¶*Return value*

          Returns a map with the response data:

          | [![width: 15%]] | [![width: 85%]]                  |
          | :status         | The HTTP status (a long)         |
          | :mimetype       | The content type's mimetype      |
          | :headers        | A map of headers. key: header name, value: list \
                              of header values |
          | :message        | The final chat completion message if the OpenAI \
                              server returned the HTTP status `HTTP_OK`, else `nil` |
          | :data           | If the response' HTTP status is `HTTP_OK` \
                              the data fields contains the chat completion \
                              message.  ¶\
                              If the response' HTTP status is not `HTTP_OK` \
                              the data fields contains an error message \
                              formatted as plain or JSON string. |
          
          ¶*Note: The streaming mode does not support functions!*
 
          See:
          * [OpenAI Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)¶
          * [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat/create)
          * [OpenAI API Messages](https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages)
          * [OpenAI API Examples](https://platform.openai.com/examples)
          * [OpenAI API Examples Prompts](https://platform.openai.com/examples?category=code)
          """ 
     :examples '(
          """
          ;; synchronous
          ;; prints the arriving events asynchronously, the response is only
          ;; returned when the final message is available or the request is bad
          (do
            (load-module :openai)
          
            (let [prompt    (str "Count to 10, with a comma between each number "
                                 "and no newlines. E.g., 1, 2, 3, ...")
                  handler   (fn [delta accumulated status]
                              (case status
                                :opened  (println "Started...")
                                :data    (println "Delta:" (pr-str delta))
                                :done    (println "Completed.")))
                  response  (openai/chat-completion-streaming prompt handler :sync true)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (pr-str (:data response)))
                (println "Error:"   (:data response)))))
          """,
          """
          ;; asynchronous
          ;; prints the arriving events asynchronously, returns the response
          ;; immediately with the data  `(:data response)` as a future that can 
          ;; be deref'd to get the final message.
          (do
            (load-module :openai)
          
            (let [prompt    (str "Count to 10, with a comma between each number "
                                 "and no newlines. E.g., 1, 2, 3, ...")
                  handler   (fn [delta accumulated status]
                              (case status
                                :opened  (println "Started...")
                                :data    (println "Delta:" (pr-str delta))
                                :done    (println "Completed.")))
                  response  (openai/chat-completion-streaming prompt handler :sync false)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (pr-str @(:data response)))
                (println "Error:"   (:data response)))))
          """ )
     :see-also '( 
          "openai/chat-completion"
          "openai/process-streaming-events" ) }

  chat-completion-streaming [prompt handler & options]

  (assert (fn? handler))

  (let [opts            (apply hash-map options)
        _               (assert (or (nil? (:prompt-opts opts)) (map? (:prompt-opts opts))))
        uri             (:uri opts "https://api.openai.com/v1/chat/completions")
        model           (:model opts default-model)
        openai-api-key  (or (:openai-api-key opts) (openai-api-key-from-env))
        _               (validate-openai-api-key openai-api-key)
        sync?           (:sync opts true)
        body            (build-prompt model prompt (:prompt-opts opts) nil {:stream true})
        debug?          (:debug opts false)
        _               (when debug? (dump-prompt body))
        response        (hc/send :post 
                          uri
                          :headers { "Content-Type" "application/json"
                                     "Authorization" (str "Bearer " openai-api-key)}
                          :body (json/write-str body)
                          :debug debug?)
        result          { :status   (:http-status response)
                          :mimetype (:content-type-mimetype response)
                          :headers  (:headers response) } ]
    (if (and (= "text/event-stream" (:content-type-mimetype response))
             (= (:http-status response) 200))
     
      (let [fr (openai/process-streaming-events response handler)]
        (assoc result :data (if sync? @fr fr)))
      (assoc result :data (hc/slurp-response response :json-parse-mode :pretty-print)))))



;; -----------------------------------------------------------------------------
;; Public utils
;; -----------------------------------------------------------------------------

(defn 
 ^{ :arglists '(
          "(process-streaming-events response handler)")
     :doc """
          Processes OpenAI server side events (SSE) and calls for every event 
          the passed handler function.
          
          Returns a `future`. This gives the caller the choice to synchronously
          or asynchronously process the events from the OpenAI server.
          
          Note: The response from the server must be of the mimetype 
                "text/event-stream" otherwise the processor throws an exception!
          
          ¶The event handler is a three argument function:
          
          `(defn handler [delta accumulated status] ...)`
          
          | *delta*       | the delta message sent with the event |
          | *accumulated* | the accumulated message |
          | *type*        | the notification type: ¶\
                            \u00A0\u00A0 `:opened` - streaming started ¶\
                            \u00A0\u00A0 `:data` - streamed event ¶\
                            \u00A0\u00A0 `:done` - streaming done by the server |
          """
     :examples '(
          """
          (do
            (load-module :openai)
            (load-module :http-client-j8 ['http-client-j8 :as 'hc])
          
            (let [api-key   (system-env "OPENAI_API_KEY")
                  content   (str "Count to 10, with a comma between each number "
                                 "and no newlines. E.g., 1, 2, 3, ...")
                  body      { :model "gpt-3.5-turbo"
                              :messages [ { :role "user"  :content content  } ]
                              :stream true } 
                  response  (hc/send :post 
                              "https://api.openai.com/v1/chat/completions"
                              :headers { "Content-Type" "application/json"
                                         "Authorization" (str "Bearer " api-key)}
                              :body (json/write-str body)
                              :debug false)]
              (println "Status:" (:http-status response))
              (if (= "text/event-stream" (:content-type-mimetype response))
                (let [text @(openai/process-streaming-events 
                                response
                                (fn [delta accumulated status]
                                  (case status
                                    :opened  (println "Started...")
                                    :data    (println "Delta:" (pr-str delta))
                                    :done    (println "Completed."))))]
                  (println "Message:" (pr-str text)))
                (println (hc/slurp-response response :json-parse-mode :pretty-print)))))
          """ )
     :see-also '( 
          "http-client-j8/slurp-response" ) }

  process-streaming-events [response handler]

  (assert (some? response))
  (assert (fn? handler))

  (when-not (= "text/event-stream" (:content-type-mimetype response))
    (throw (ex :VncException 
                """
                OpenAI server side events can only be processed on a response \
                with mimetype 'text/event-stream'!
                """)))

  ;; return a future
  (future #(do
      (let [accumulator (atom "")]
        ;; process the events
        (hc/process-server-side-events 
              response
              (fn [type event event-count]
                (case type
                  :opened (do (handler "" "" :opened)
                              :ok)
                  :data   (let [payload (first (:data event))]
                            (if (= payload "[DONE]")
                              :stop
                              (let [delta (extract-streaming-delta-content payload)]
                                (swap! accumulator str delta)
                                (handler delta @accumulator :data)
                                :ok)))
                  :closed (do (handler "" @accumulator :done)
                              :ok))))
        ;; the future returns the accumulated response text
        @accumulator))))


(defn 
  ^{ :arglists '(
          "(pretty-print-json data)")
     :doc """
          Returns a pretty printed Venice JSON data value.
          """
     :see-also '( 
          "openai/extract-response-message-content" ) }

  pretty-print-json [data]

  (if (coll? data) (json/pretty-print (json/write-str data)) data))


(defn 
  ^{ :arglists '(
          "(extract-response-message-content message)")
     :doc """
          Returns the message content of an OpenAI JSON response message.
          """
     :see-also '( 
          "openai/pretty-print-json" ) }

  extract-response-message-content [message]

  (assert (coll? message))

  (-> (:choices message)
      (first)
      (:message)
      (:content)))


(defn pretty-print-conversation [messages]
  (doseq [m messages]
    (let [{:keys [role content]}  m]
      (case role
        :system     (println (ansi/style (str "system: " content) 
                                         (:bright-red ansi/ANSI-CODES)))
        :user       (println (ansi/style (str "user: " content) 
                                         (:bright-green ansi/ANSI-CODES)))
        :assistant  (println (ansi/style (str "assistant: " content) 
                                         (:bright-blue ansi/ANSI-CODES)))
        :function   (println (ansi/style (str "function: " content) 
                                         (:bright-magenta ansi/ANSI-CODES)))))))
                                         

;; -----------------------------------------------------------------------------
;; Util functions
;; -----------------------------------------------------------------------------

(defn- extract-streaming-delta-content [payload]
  (-> (json/read-str payload :key-fn keyword)
      (:choices)
      (first)
      (:delta)
      (:content)))


(defn- openai-api-key-from-env [] 
  (system-env "OPENAI_API_KEY"))


(defn- build-prompt [model prompt prompt-opts tools overrule-opts]
  (let [p (cond 
            (nil? prompt)        {}
            (string? prompt)     {:messages [{:role "user" :content prompt}]}
            (sequential? prompt) {:messages prompt}
            (map? prompt)        prompt
            :else                {} )
        t (if (nil? tools) {} {:tools tools})]
    (merge {:model (or model default-model)} 
           p 
           t
           (or prompt-opts {})
           (or overrule-opts {}))))

  
(defn- dump-prompt [prompt]
  (println "\nPrompt:")
  (println (json/pretty-print (json/write-str prompt))))


(defn- demo-functions []
  [ 
    { :type "function" 
      :function {
          :name "get_current_weather"
          :description "Get the current weather"
          :parameters {
              :type "object"
              :properties {
                  :location {
                      :type "string"
                      :description "The city and state, e.g. San Francisco, CA"
                  }
                  :format {
                      :type "string"
                      :enum ["celsius", "fahrenheit"]
                      :description "The temperature unit to use. Infer this from the users location."
                  }
              }
              :required ["location", "format"]
          } } }
    { :type "function"
      :function {
          :name "get_n_day_weather_forecast"
          :description "Get an N-day weather forecast"
          :parameters {
              :type "object"
              :properties {
                  :location {
                      :type "string"
                      :description "The city and state, e.g. San Francisco, CA"
                  }
                  :format {
                      :type "string"
                      :enum ["celsius", "fahrenheit"]
                      :description "The temperature unit to use. Infer this from the users location."
                  }
                  :num_days {
                      :type "integer"
                      :description "The number of days to forecast"
                  }
              }
              :required ["location", "format", "num_days"]
          } } }
  ] )


(defn- validate-openai-api-key [key]
  (when (nil? key)
    (throw (ex :VncException 
               """
               Missing OpenAI api key!
               Please define an environment variable with the name \
               "OPENAI_API_KEY" or pass the key as an option \
               `:openai-api-key "sk-xxxxxxxxxxxxx"`.
               """))))


(defn- validate-tools [tools]
  (when (some? tools)
    (when-not (sequential? tools)
      (throw (ex :VncException 
                  """
                  OpenAI Tools options must be `nil` or a sequence of maps!

                  E.g.:

                  [ { :type "function" 
                      :function {
                          :name "get_current_weather"
                          :description "Get the current weather"
                          :parameters { ... }
                      } } ]

                 """)))))
