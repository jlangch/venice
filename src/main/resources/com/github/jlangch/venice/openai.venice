;;;;   __    __         _
;;;;   \ \  / /__ _ __ (_) ___ ___
;;;;    \ \/ / _ \ '_ \| |/ __/ _ \
;;;;     \  /  __/ | | | | (_|  __/
;;;;      \/ \___|_| |_|_|\___\___|
;;;;
;;;;
;;;; Copyright 2017-2024 Venice
;;;;
;;;; Licensed under the Apache License, Version 2.0 (the "License");
;;;; you may not use this file except in compliance with the License.
;;;; You may obtain a copy of the License at
;;;;
;;;;     http://www.apache.org/licenses/LICENSE-2.0
;;;;
;;;; Unless required by applicable law or agreed to in writing, software
;;;; distributed under the License is distributed on an "AS IS" BASIS,
;;;; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
;;;; See the License for the specific language governing permissions and
;;;; limitations under the License.

;;;; OpenAI API


(ns openai)

(load-module :http-client-j8 ['http-client-j8 :as 'hc])


;; =============================================================================
;; =                                                                           =
;; =                     W O R K   I N   P R O G R E S S                       =
;; =                                                                           =
;; =============================================================================


;; -----------------------------------------------------------------------------
;; MODELS 
;; -----------------------------------------------------------------------------

;; see https://platform.openai.com/docs/models/continuous-model-upgrades

(def gpt-4-turbo   "gpt-4.0-turbo")    ;; GPT-4 Turbo with Vision, 128'000 tokens
(def gpt-4         "gpt-4")            ;; GPT-4, 8'192 tokens
(def gpt-4-32k     "gpt-4-32k")        ;; GPT-4, 32'768 tokens
(def gpt-3.5-turbo "gpt-3.5-turbo")    ;; GPT-3.5, 16'385 tokens

(def dall-e-3      "dall-e-3")         ;; DALL-E 3
(def dall-e-2      "dall-e-2")         ;; DALL-E 2

(def tts-1         "tts-1")            ;; Text-to-speech 1
(def tts-1-hd      "tts-1-hd")         ;; Text-to-speech 1 HD

(def whisper-1     "whisper-1")        ;; Whisper, general-purpose speech recognition

(def text-embedding-3-large  "text-embedding-3-large")   ;; Text embedding, dimension 3'072
(def text-embedding-3-small  "text-embedding-3-small")   ;; Text embedding, dimension 1'536
(def text-embedding-ada-002  "text-embedding-ada-002")   ;; Text embedding, dimension 1'536




;; -----------------------------------------------------------------------------
;; CHAT COMPLETIONS 
;; -----------------------------------------------------------------------------

;; https://platform.openai.com/docs/guides/text-generation
;; https://platform.openai.com/docs/api-reference/chat/create

(def endpoint-gpt-new "https://api.openai.com/v1/chat/completions")
(def endpoint-gpt-old "https://api.openai.com/v1/completions")



;; a very first test, to test credentials and API credits
(defn chat-completion-test []
  (let [body      { :model "gpt-3.5-turbo"
                    :messages [ { :role "user"
                                  :content """
                                           Count to 10, with a comma between each number \
                                           and no newlines. E.g., 1, 2, 3, ...
                                           """ } ] } 
        response  (hc/send :post 
                    "https://api.openai.com/v1/chat/completions"
                    :headers { "Content-Type" "application/json"
                               "Authorization" "Bearer ~(openai-api-key)"}
                    :body (json/write-str body)
                    :debug false)]
    (println "Status:" (:http-status response))
    (println (hc/slurp-response response :json-parse-mode :pretty-print))))

(comment
    ;; response from OpenAI

    """
    {
      "created": 1713302066,
      "usage": {
        "completion_tokens": 28,
        "prompt_tokens": 37,
        "total_tokens": 65
      },
      "model": "gpt-3.5-turbo-0125",
      "id": "chatcmpl-9EkQE6O4khw25Fi8MLUvRsu36lfrn",
      "choices": [{
        "finish_reason": "stop",
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "1, 2, 3, 4, 5, 6, 7, 8, 9, 10"
        },
        "logprobs": null
      }],
      "system_fingerprint": "fp_c2295e73ad",
      "object": "chat.completion"
    }
    """ )

(defn chat-completion-streaming-test []
  (let [body      { :model "gpt-3.5-turbo"
                    :messages [ { :role "user"
                                  :content """
                                           Count to 10, with a comma between each number \
                                           and no newlines. E.g., 1, 2, 3, ...
                                           """ } ]
                    :stream true } 
        response  (hc/send :post 
                    "https://api.openai.com/v1/chat/completions"
                    :headers { "Content-Type" "application/json"
                               "Authorization" "Bearer ~(openai-api-key)"}
                    :body (json/write-str body)
                    :debug false)]
    (println "Status:" (:http-status response))
    (if (= "text/event-stream" (:content-type-mimetype response))
      (process-streaming-events 
                  response
                  (fn [delta accumulated status]
                    (case status
                      :opened (println "Started...")
                      :data   (println "Message delta:" (pr-str delta))
                      :done   (println "Message:" (pr-str accumulated)))))
      (println (hc/slurp-response response :json-parse-mode :pretty-print)))))



;; -----------------------------------------------------------------------------
;; Public utils
;; -----------------------------------------------------------------------------

(defn 
 ^{ :arglists '(
          "(process-streaming-events response mode handler timeout)")
     :doc """
          Processes OpenAI server side events (SSE) and calls for every event the
          handler 'handler'.

          Note: The response must be of the mimetype "text/event-stream"
                otherwise the processor throws an exception!

          The mode is either :sync or :async. In async mode the handler function 
          returns immediately and asynchronously processes the events received.
          In sync mode the handler blocks, processed the events received and 
          returns the accumulated message when all events have been received.
          
          The event handler throws a :com.github.jlangch.venice.TimeoutException 
          if the server times out sending events.

          The event handler is a three argument function:
          
          `(defn handler [delta accumulated status] ...)`

          | *delta*       | the delta message sent with the event |
          | *accumulated* | the accumulated message|
          | *type*        | the notification type: ¶\
                            \u00A0\u00A0 `:opened` - streaming started ¶\
                            \u00A0\u00A0 `:data` - streamed event ¶\
                            \u00A0\u00A0 `:done` - streaming done by the server |

          The timout is given in seconds. A zero or negative value means an
          infinite timeout.
          """ 
     :examples '(
          """
          (do
            (load-module :openai)

            (let [body      { :model "gpt-3.5-turbo"
                              :messages [ { :role "user"
                                            :content """
                                                    Count to 10, with a comma between each number \
                                                    and no newlines. E.g., 1, 2, 3, ...
                                                    """ } ]
                              :stream true } 
                  response  (hc/send :post 
                              "https://api.openai.com/v1/chat/completions"
                              :headers { "Content-Type" "application/json"
                                        "Authorization" "Bearer ~(openai-api-key)"}
                              :body (json/write-str body)
                              :debug false)]
              (println "Status:" (:http-status response))
              (if (= "text/event-stream" (:content-type-mimetype response))
                (process-streaming-events 
                            response
                            :async
                            (fn [delta accumulated status]
                              (case status
                                :opened (println "Started...")
                                :data   (println "Message delta:" (pr-str delta))
                                :done   (println "Message:" (pr-str accumulated))))
                            -1)
                (println (hc/slurp-response response :json-parse-mode :pretty-print)))))
          """ ) }

  process-streaming-events [response mode handler timeout]

  (assert (some? response))
  (assert (and (keyword? mode) (contains #{:sync :async} mode)))
  (assert (fn? handler))
  (assert (long? tiemout))

  (when-not (= "text/event-stream" (:content-type-mimetype response))
    (throw (ex :VncException 
                """
                OpenAI server side events can only be processed on a response \
                with mimetype 'text/event-stream'!
                """)))

  (when (= mode :sync)
    (throw (ex :VncException "Sync mode is not yet implemented!")))

  (when (pos? timeout)
    (throw (ex :VncException "Timeouts are not yet implemented!")))

  ;; process the events
  (hc/process-server-side-events 
        response
        (let [accumulator (atom "")]
          (fn [type event event-count]
            (case type
              :opened (do 
                        (handler "" "" :opened)
                        :ok)
              :data   (let [payload (first (:data event))]
                        (if (= payload "[DONE]")
                          :stop
                          (let [delta (extract-streaming-delta-content payload)]
                            (swap! accumulator str delta)
                            (handler delta @accumulator :data)
                            :ok)))
              :closed (do
                        (handler "" @accumulator :done)
                        :ok))))))



;; -----------------------------------------------------------------------------
;; Private utils
;; -----------------------------------------------------------------------------

(defn- extract-streaming-delta-content [payload]
  (-> (json/read-str payload :key-fn keyword)
      (:choices)
      (first)
      (:delta)
      (:content)))


(defn- openai-api-key [] (system-env "OPENAI_API_KEY"))
