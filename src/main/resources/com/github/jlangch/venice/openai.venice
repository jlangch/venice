;;;;   __    __         _
;;;;   \ \  / /__ _ __ (_) ___ ___
;;;;    \ \/ / _ \ '_ \| |/ __/ _ \
;;;;     \  /  __/ | | | | (_|  __/
;;;;      \/ \___|_| |_|_|\___\___|
;;;;
;;;;
;;;; Copyright 2017-2024 Venice
;;;;
;;;; Licensed under the Apache License, Version 2.0 (the "License");
;;;; you may not use this file except in compliance with the License.
;;;; You may obtain a copy of the License at
;;;;
;;;;     http://www.apache.org/licenses/LICENSE-2.0
;;;;
;;;; Unless required by applicable law or agreed to in writing, software
;;;; distributed under the License is distributed on an "AS IS" BASIS,
;;;; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
;;;; See the License for the specific language governing permissions and
;;;; limitations under the License.

;;;; OpenAI client without any dependencies on 3rd party libraries


(ns openai)

(load-module :http-client-j8 ['http-client-j8 :as 'hc])


;; =============================================================================
;; =                                                                           =
;; =                     W O R K   I N   P R O G R E S S                       =
;; =                                                                           =
;; =============================================================================


;; -----------------------------------------------------------------------------
;; MODELS 
;; -----------------------------------------------------------------------------

;; see https://platform.openai.com/docs/models/continuous-model-upgrades

(def gpt-4-turbo   "gpt-4.0-turbo")    ;; GPT-4 Turbo with Vision, 128'000 tokens
(def gpt-4         "gpt-4")            ;; GPT-4, 8'192 tokens
(def gpt-4-32k     "gpt-4-32k")        ;; GPT-4, 32'768 tokens
(def gpt-3.5-turbo "gpt-3.5-turbo")    ;; GPT-3.5, 16'385 tokens

(def dall-e-3      "dall-e-3")         ;; DALL-E 3
(def dall-e-2      "dall-e-2")         ;; DALL-E 2

(def tts-1         "tts-1")            ;; Text-to-speech 1
(def tts-1-hd      "tts-1-hd")         ;; Text-to-speech 1 HD

(def whisper-1     "whisper-1")        ;; Whisper, general-purpose speech recognition

(def text-embedding-3-large  "text-embedding-3-large")   ;; Text embedding, dimension 3'072
(def text-embedding-3-small  "text-embedding-3-small")   ;; Text embedding, dimension 1'536
(def text-embedding-ada-002  "text-embedding-ada-002")   ;; Text embedding, dimension 1'536




;; -----------------------------------------------------------------------------
;; CHAT COMPLETIONS 
;; -----------------------------------------------------------------------------

;; https://platform.openai.com/docs/guides/text-generation
;; https://platform.openai.com/docs/api-reference/chat/create

(def endpoint-gpt-new "https://api.openai.com/v1/chat/completions")
(def endpoint-gpt-old "https://api.openai.com/v1/completions")


(defn 
  ^{ :arglists '(
          "(chat-completion messages & options)" )
     :doc """
          Runs a chat completion.

          *Note: Function support is coming soon!*

          To run the request asynchronously just wrap it in a `future` and
          deref it, when the result is required.

          Parameter messages: See [Message API](https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages)

          ¶¶*Request Options:*

          | [![width: 15%]]    | [![width: 85%]] |
          | :uri               | An OpenAI chat completion uri. E.g.: \
                                 "https://api.openai.com/v1/chat/completions". \
                                 Defaults  to "https://api.openai.com/v1/chat/completions" |
          | :model             | An OpenAI model. E.g.: "gpt-3.5-turbo". Defaults \
                                 to "gpt-3.5-turbo" |
          | :request-body      | An optional map of OpenAI chat request body fields ¶\
                                 E.g. {"temperature" 0.2}
                                 See: [Request Options](https://platform.openai.com/docs/api-reference/chat/create) |
          | :openai-api-key    | An optional OpenAI API Key. As default the key is read \
                                 from the environment variable "OPENAI_API_KEY". |
          | :debug             | An optional debug flag (true/false). Defaults \
                                 to false. ¶\
                                 In debug mode prints the HTTP request and response data |
 
          *Returns a map with the response data:*

          | [![width: 15%]] | [![width: 85%]]                  |
          | :status         | The HTTP status (a long)         |
          | :mimetype       | The content type's mimetype      |
          | :headers        | A map of headers. key: header name, value: list \
                              of header values |
          | :message        | The final chat completion message if the OpenAI \
                              server returned the HTTP status OK, else `nil` |
          | :data           | If the response' HTTP status is `HTTP_OK` \
                              the data fields contains the chat completion \
                              message ¶\
                              If the response' HTTP status is not `HTTP_OK` \
                              the data fields contains an error message \
                              formatted as plain or JSON string |

          ¶
          See: [Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)
          See: [API Reference](https://platform.openai.com/docs/api-reference/chat/create)
          """ 
     :examples '(
          """
          ;; print the full OpenAI response message
          (do
            (load-module :openai)

            (let [message   "Count to 10, with a comma between each number and no newlines. E.g., 1, 2, 3, ..."
                  response  (openai/chat-completion message)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (openai/pretty-print-json (:data response)))
                (println "Error:"   (:data response)))))
          """,
          """
          ;; print only the OpenAI response message content
          (do
            (load-module :openai)

            (let [message   "Count to 10, with a comma between each number and no newlines. E.g., 1, 2, 3, ..."
                  response  (openai/chat-completion message)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (-> (:data response)
                                        (openai/extract-response-message-content)
                                        (pr-str)))
                (println "Error:"   (:data response)))))
          """ )
     :see-also '( 
          "openai/chat-completion-streaming"
          "openai/extract-response-message-content"
          "openai/pretty-print-json" ) }

  chat-completion [messages & options]

  (validate-message-or-messages messages)

  (let [opts           (apply hash-map options)
        uri            (:uri opts "https://api.openai.com/v1/chat/completions")
        model          (:model opts "gpt-3.5-turbo")
        openai-api-key (or (:openai-api-key opts) (openai-api-key-from-env))
        request-body   (:request-body opts {})
        _              (assert (map? request-body))
        body           (merge
                         { :model model
                           :messages  (if (string? messages)
                                        [{:role "user" :content messages}]
                                        messages) }
                         request-body
                         {:stream false}) 
        response       (hc/send :post 
                         uri
                         :headers { "Content-Type" "application/json"
                                    "Authorization" (str "Bearer " openai-api-key)}
                         :body (json/write-str body)
                         :debug (:debug opts false))
        result         { :status   (:http-status response)
                         :mimetype (:content-type-mimetype response)
                         :headers  (:headers response) } ]
   (assoc result :data   (hc/slurp-response response 
                                            :json-parse-mode :data 
                                            :json-key-fn keyword))))


(defn 
 ^{ :arglists '(
          "(chat-completion-streaming messages handler & options)" )
     :doc """
          Runs a chat completion in streaming mode.

          Processes OpenAI server side events (SSE) and calls for every event the
          handler 'handler'.
        
          The event handler is a three argument function:
          
          `(defn handler [delta accumulated status] ...)`

          | *delta*       | the delta message sent with the event |
          | *accumulated* | the accumulated message|
          | *type*        | the notification type: ¶\
                            \u00A0\u00A0 `:opened` - streaming started ¶\
                            \u00A0\u00A0 `:data` - streamed event ¶\
                            \u00A0\u00A0 `:done` - streaming done by the server |

          ¶¶*Request Options:*

          | [![width: 15%]]    | [![width: 85%]] |
          | :uri               | An OpenAI chat completion uri. E.g.: \
                                 "https://api.openai.com/v1/chat/completions". \
                                 Defaults  to "https://api.openai.com/v1/chat/completions" |
          | :model             | An OpenAI model. E.g.: "gpt-3.5-turbo". Defaults \
                                 to "gpt-3.5-turbo" |
          | :sync              | if *true* runs the request syncronously and waits \
                                 until the full message response is available. ¶\
                                 if *false* runs the request asyncronously and \
                                 returns immediately with the response :data \
                                 field holding a `future` that can be derefed  \
                                 (with an optional timeout) to get the full \
                                 message. ¶\
                                 Defaults to *true* |
          | :request-body      | An optional map of OpenAI chat request body fields ¶\
                                 E.g. {"temperature" 0.2}
                                 See: [Request Options](https://platform.openai.com/docs/api-reference/chat/create) |
          | :openai-api-key    | An optional OpenAI API Key. As default the key is read \
                                 from the environment variable "OPENAI_API_KEY". |
          | :debug             | An optional debug flag (true/false). Defaults \
                                 to false. ¶\
                                 In debug mode prints the HTTP request and response data |
 
          *Returns a map with the response data:*

          | [![width: 15%]] | [![width: 85%]]                  |
          | :status         | The HTTP status (a long)         |
          | :mimetype       | The content type's mimetype      |
          | :headers        | A map of headers. key: header name, value: list \
                              of header values |
          | :message        | The final chat completion message if the OpenAI \
                              server returned the HTTP status OK, else `nil` |
          | :data           | If the response' HTTP status is `HTTP_OK` \
                              the data fields contains the chat completion \
                              message  ¶\
                              If the response' HTTP status is not `HTTP_OK` \
                              the data fields contains an error message \
                              formatted as plain or JSON string |
          
          ¶*Note: The streaming mode does not support functions!*
 
          See: [Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)
          See: [API Reference](https://platform.openai.com/docs/api-reference/chat/create)
          """ 
     :examples '(
          """
          ;; synchronous
          (do
            (load-module :openai)
          
            (let [message   "Count to 10, with a comma between each number and no newlines. E.g., 1, 2, 3, ..."
                  handler   (fn [delta accumulated status]
                              (case status
                                :opened  (println "Started...")
                                :data    (println "Delta:" (pr-str delta))
                                :done    (println "Completed.")))
                  response  (openai/chat-completion-streaming message handler)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (pr-str (:data response)))
                (println "Error:"   (:data response)))))
          """,
          """
          ;; asynchronous
          (do
            (load-module :openai)
          
            (let [message   "Count to 10, with a comma between each number and no newlines. E.g., 1, 2, 3, ..."
                  handler   (fn [delta accumulated status]
                              (case status
                                :opened  (println "Started...")
                                :data    (println "Delta:" (pr-str delta))
                                :done    (println "Completed.")))
                  response  (openai/chat-completion-streaming message handler :sync false)]
              (println "Status:  " (:status response))
              (println "Mimetype:" (:mimetype response))
              (if (=  (:status response) 200)
                (println "Message:" (pr-str @(:data response)))
                (println "Error:"   (:data response)))))
          """ )
     :see-also '( 
          "openai/chat-completion"
          "openai/process-streaming-events" ) }

  chat-completion-streaming [messages handler & options]

  (assert (fn? handler))

  (validate-message-or-messages messages)

  (let [opts           (apply hash-map options)
        uri            (:uri opts "https://api.openai.com/v1/chat/completions")
        model          (:model opts "gpt-3.5-turbo")
        openai-api-key (or (:openai-api-key opts) (openai-api-key-from-env))
        sync?          (:sync opts true)
        request-body   (:request-body opts {})
        _              (assert (map? request-body))
        body           (merge
                         { :model model
                           :messages  (if (string? messages)
                                        [{:role "user" :content messages}]
                                        messages) }
                         request-body
                         {:stream true}) 
        response       (hc/send :post 
                         uri
                         :headers { "Content-Type" "application/json"
                                    "Authorization" (str "Bearer " openai-api-key)}
                         :body (json/write-str body)
                         :debug (:debug opts false))
        result         { :status   (:http-status response)
                         :mimetype (:content-type-mimetype response)
                         :headers  (:headers response) } ]
    (if (and (= "text/event-stream" (:content-type-mimetype response))
             (= (:http-status response) 200))
     
      (let [fr (openai/process-streaming-events response handler)]
        (assoc result :data (if sync? @fr fr)))
      (assoc result :data (hc/slurp-response response :json-parse-mode :pretty-print)))))



;; -----------------------------------------------------------------------------
;; Public utils
;; -----------------------------------------------------------------------------

(defn 
 ^{ :arglists '(
          "(process-streaming-events response handler)")
     :doc """
          Processes OpenAI server side events (SSE) and calls for every event the
          handler 'handler'.
          
          Returns a future. This gives the caller the choice to synchronously
          or asynchronously process the events from the OpenAI server.
          
          Note: The response must be of the mimetype "text/event-stream"
                otherwise the processor throws an exception!
          
          The event handler is a three argument function:
          
          `(defn handler [delta accumulated status] ...)`
          
          | *delta*       | the delta message sent with the event |
          | *accumulated* | the accumulated message |
          | *type*        | the notification type: ¶\
                            \u00A0\u00A0 `:opened` - streaming started ¶\
                            \u00A0\u00A0 `:data` - streamed event ¶\
                            \u00A0\u00A0 `:done` - streaming done by the server |
          """
     :examples '(
          """
          (do
            (load-module :openai)
            (load-module :http-client-j8 ['http-client-j8 :as 'hc])
          
            (let [api-key   (system-env "OPENAI_API_KEY")
                  body      { :model "gpt-3.5-turbo"
                              :messages [ { :role "user"
                                            :content "Count to 10, with a comma between each number and no newlines. E.g., 1, 2, 3, ..."
                                          } ]
                              :stream true } 
                  response  (hc/send :post 
                              "https://api.openai.com/v1/chat/completions"
                              :headers { "Content-Type" "application/json"
                                         "Authorization" (str "Bearer " api-key)}
                              :body (json/write-str body)
                              :debug false)]
              (println "Status:" (:http-status response))
              (if (= "text/event-stream" (:content-type-mimetype response))
                (let [text @(openai/process-streaming-events 
                                response
                                (fn [delta accumulated status]
                                  (case status
                                    :opened  (println "Started...")
                                    :data    (println "Delta:" (pr-str delta))
                                    :done    (println "Completed."))))]
                  (println "Message:" (pr-str text)))
                (println (hc/slurp-response response :json-parse-mode :pretty-print)))))
          """ )
     :see-also '( 
          "http-client-j8/slurp-response" ) }

  process-streaming-events [response handler]

  (assert (some? response))
  (assert (fn? handler))

  (when-not (= "text/event-stream" (:content-type-mimetype response))
    (throw (ex :VncException 
                """
                OpenAI server side events can only be processed on a response \
                with mimetype 'text/event-stream'!
                """)))

  ;; return a future
  (future #(do
      (let [accumulator (atom "")]
        ;; process the events
        (hc/process-server-side-events 
              response
              (fn [type event event-count]
                (case type
                  :opened (do (handler "" "" :opened)
                              :ok)
                  :data   (let [payload (first (:data event))]
                            (if (= payload "[DONE]")
                              :stop
                              (let [delta (extract-streaming-delta-content payload)]
                                (swap! accumulator str delta)
                                (handler delta @accumulator :data)
                                :ok)))
                  :closed (do (handler "" @accumulator :done)
                              :ok))))
        ;; the future returns the accumulated response text
        @accumulator))))


(defn 
  ^{ :arglists '(
          "(pretty-print-json data)")
     :doc """
          Returns a pretty printed Venice JSON data value.
          """
     :see-also '( 
          "openai/extract-response-message-content" ) }

  pretty-print-json [data]

  (if (coll? data) (json/pretty-print (json/write-str data)) data))


(defn 
  ^{ :arglists '(
          "(extract-response-message-content message)")
     :doc """
          Returns the message content of an OpenAI JSON response message.
          """
     :see-also '( 
          "openai/pretty-print-json" ) }

  extract-response-message-content [message]

  (assert (coll? messsage))

  (-> (:choices message)
      (first)
      (:message)
      (:content)))



;; -----------------------------------------------------------------------------
;; Util functions
;; -----------------------------------------------------------------------------

(defn- extract-streaming-delta-content [payload]
  (-> (json/read-str payload :key-fn keyword)
      (:choices)
      (first)
      (:delta)
      (:content)))


(defn- openai-api-key-from-env [] 
  (system-env "OPENAI_API_KEY"))



;; -----------------------------------------------------------------------------
;; Validator functions
;; -----------------------------------------------------------------------------

(defn- validate-message-or-messages [messages]
  (cond 
    (string? messages)     true
    (sequential? messages) (validate-message-list messages)
    :else                  (throw (ex :VncException (get-invalid-message-error)))))


(defn- validate-message-list [messages]
  (doseq [m messages]
         (if (map? m)
           (validate-message-map messages)
           (throw (ex :VncException (get-invalid-message-error))))))


(defn- validate-message-map [message]
  (let [valid-keys #{:role :content}] 
    ;; all keys must be :role or :conten keywords
    (when-not (every? #(some? (get valid-keys %)) (keys message))
      (throw (ex :VncException (get-invalid-message-error))))
    ;; all values must be strings
    (when-not (every? string? (vals message))
      (throw (ex :VncException (get-invalid-message-error))))))


(defn get-invalid-message-error []
  """
  Invalid message/messages!
  Must be a string or list/vector of role/content maps \
  { :role "role" :content "content" }
  """ )
